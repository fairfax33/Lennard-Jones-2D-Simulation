{"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.14"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"80fec942-936a-403f-9e8d-78d6d8767d68","cell_type":"code","source":"#Cell 1: Read ME!\n\"\"\"\nCELL 1: Read Me\n\nCells 2-4 are initilization of simulator\n\nCell 5 initializes a full-control simulator named \"sim\"\n\nCell 6 initializes helper functions to scale particle & quiver size\n\nCell 7 generates visualization of first N steps for sim, also where you set frame & capture rate\n\nCell 8 runs a pure physics simulation of first N steps for sim, also optionally generates 1st & last frames\n\nCell 9 generates any visualization created in previous 2 steps\n\nCell 10 is 2 helper functions to help with MB calculations\n\nCell 11 is a mega plotting function that graphs actual velocity distribution x expected, along with quantifiable error metrics (L1 is most helpful imo)\n\nCell 12 creates a new simulator instance and runs N steps, taking a snapshot (saves particle velocities) at user-defined intervals\n\nCell 13 visualizes convergence to MB from constant velocity\n\nCell 14 visualizes adherence to MB of a particular snapshot / final state\n\nCell 15 initializes real CPU runtime of Simulator class for 50 steps x theoretical GPU runtime\n\nCell 16 runs & plots function from cell 15\n\nUseful Notes:\n\n- Inside cell 5, simulation settings can be modified for visualization.\n    There are sample combinations provided inside quotations that will not crash the program\n\n- Inside cell 7 there are visualization settings. It is possible to increase framerate picture quality, and # of frames captured, but not recommended to do so.\n    Oftentimes, the reason the simulation crashes is due to too many frames with too many pixels overloading the storage\n    It is a good idea to not exceed 1000 steps of 300 particles for 6 frames captured per second displayed at 45 frames per second, with an 8 inch length x 80 pixel clarity. \n    \n- Inside cell 11 there is a total_bins variable that can be modified to plot the simulated particles using a user_defined amount of bins.\n\n- The variables at the top of cell 12 can be modified to create more intensive pure-physics simulations. There is no worry about overloading RAM here, as the particles & calculations themselves do not take up much storage.\n    The main limitation is how long the user is willing to sit at their desk while the simulation runs\n    A simulation of 100,000 particles for 10,000 steps will take ~ ___ seconds to run on a Macbook Air M4\n\n\n- To view the difference in runtime between Numba compilation & running in pure python: \n    After running each cell in the notebook, comment out the @njit decorators above each function inside Cell 3\n    Then, run cell 3 to update changes\n    Then, run cell 16.\n    Warning: before doing this, I recommend changing the up_to varible inside cell 16 to something lesser, like 8, and adjusting + observing runtime changes from there\n    (You should see ~100x slowdown in the early stages)\n\"\"\"\nprint(\"read me\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"53e1d1a4-9fbc-4d21-a9e1-2b09290749ab","cell_type":"code","source":"#Cell 2\n!pip install imageio\n!pip install numba\n#imports & configuration\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport imageio.v2 as imageio\nimport io\nimport time\nimport os\nimport gc\nimport contextlib\nfrom numba import njit, float64, int32\nfrom IPython.display import Image, display\nfrom scipy.stats import maxwell\n\n#Set plot style\nplt.style.use('ggplot')\nprint(\"Imports successful\")\nprint(os.getcwd())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"7531843b-5bb9-42e6-a8a5-0e55e181a7cd","cell_type":"code","source":"#Cell 3\n#Physics kernels used in simulation class\n#These use numba JIT compiler (njit decorator) to reduce runtime\n@njit(cache=True)\ndef pbc_dist(r1, r2, box_L):\n    \"\"\"\n    Minimum image convention: calculates shortest distance vector (dx, dy) and squared distance (r2)\n    under periodic boundary conditions\n    \"\"\"\n    dx = r1[0] - r2[0]\n    dy = r1[1] - r2[1]\n\n    #Wrapping logic for minimum image convention:\n    #Wrap dx/dy if they exceed L/2 (particles are closer if they wrap around the boundary)\n    if dx > box_L * 0.5: \n        dx -= box_L\n    elif dx < -box_L * 0.5: \n        dx += box_L\n    \n    if dy > box_L * 0.5: \n        dy -= box_L\n    elif dy < -box_L * 0.5: \n        dy += box_L\n\n    #Return r2 (memory trick)\n        #LJ potential depends on r^-6 and r^-12 which can be calculated directly from r^2 without a square root\n    r2 = dx*dx + dy*dy\n    return dx, dy, r2\n\n@njit(cache=True)\ndef compute_forces_cell_list(pos, box_L, rcut, epsilon, sigma):\n    N = pos.shape[0]\n    forces = np.zeros((N, 2), dtype=np.float64)\n    pot_energy = 0.0\n\n    rcut2 = rcut * rcut\n    cell_size = rcut\n    nx = int(box_L / cell_size)\n    if nx < 1:\n        nx = 1\n    ny = nx\n    \n    cell_heads = -1 * np.ones(nx * ny, dtype=np.int32)\n    linked_list = -1 * np.ones(N, dtype=np.int32)\n\n    #Assign each particle to a cell\n    for i in range(N):\n        cx = int(pos[i, 0] / cell_size)\n        cy = int(pos[i, 1] / cell_size)\n\n        if cx < 0:\n            cx = 0\n        elif cx >= nx:\n            cx = nx - 1\n        if cy < 0:\n            cy = 0\n        elif cy >= ny:\n            cy = ny - 1\n\n        c_index = cx + cy * nx\n        linked_list[i] = cell_heads[c_index]\n        cell_heads[c_index] = i\n\n    #Lennard jones constants\n    sig2 = sigma * sigma\n    sig6 = sig2 * sig2 * sig2\n    sig12 = sig6 * sig6\n    force_pre = 24.0 * epsilon\n    pe_pre = 4.0 * epsilon\n\n    #Loop over cells and neighbors\n    for cy in range(ny):\n        for cx in range(nx):\n\n            c = cx + cy * nx\n            i = cell_heads[c]\n\n            #Loop over particles in this cell\n            while i != -1:\n\n                #Loop over neighboring cells (3×3 region)\n                for off_y in (-1, 0, 1):\n                    for off_x in (-1, 0, 1):\n\n                        ncx = cx + off_x\n                        ncy = cy + off_y\n\n                        #Periodic wrap\n                        if ncx < 0:\n                            ncx += nx\n                        elif ncx >= nx:\n                            ncx -= nx\n                        if ncy < 0:\n                            ncy += ny\n                        elif ncy >= ny:\n                            ncy -= ny\n\n                        nc = ncx + ncy * nx\n                        j = cell_heads[nc]\n\n                        #Loop over particles in neighbor cell\n                        while j != -1:\n\n                            if j > i:   #Avoid double counting\n                                dx_r, dy_r, r2 = pbc_dist(pos[i], pos[j], box_L)\n\n                                if r2 < rcut2 and r2 > 1e-12:\n                                    r2_inv = 1.0 / r2\n                                    r6_inv = r2_inv * r2_inv * r2_inv\n                                    term6 = sig6 * r6_inv\n                                    term12 = term6 * term6\n\n                                    f_scalar = (force_pre * r2_inv) * (2.0 * term12 - term6)\n                                    fx = f_scalar * dx_r\n                                    fy = f_scalar * dy_r\n\n                                    forces[i, 0] += fx\n                                    forces[i, 1] += fy\n                                    forces[j, 0] -= fx\n                                    forces[j, 1] -= fy\n\n                                    pot_energy += pe_pre * (term12 - term6)\n\n                            j = linked_list[j]\n\n                i = linked_list[i]\n\n    return forces, pot_energy\nprint(\"Kernels initialized\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"3d7ccb6f-c743-48c4-bce9-298b2b1fb961","cell_type":"code","source":"#Cell 4\n#Simulation class\nclass Simulator:\n    def __init__(self, N=200, L=20.0, dt=0.002, rcut=2.5, epsilon=1.0, sigma=1.0, mass=1.0, init_mode=\"random\", speed0=1.0, target_density=0.8):\n        self.N = N\n        self.dt = dt\n        self.rcut = rcut\n        self.epsilon = epsilon\n        self.sigma = sigma\n        self.mass = mass\n        #natural time unit calculation\n        tau = self.sigma * np.sqrt(self.mass / self.epsilon)\n        print(f\"tau = {tau}\")\n        dt = 0.002 * tau\n        print(f\"dt = {dt}\")\n\n        \"\"\"\n        #Dont uncomment this, its js an example\n        simulation for argon:\n        sim_Argon = Simulator(n=2000, L=NONE, epsilon = 1.65e-21, sigma = 3.4e-10, mass = 6.63e-26)\n        \"\"\"\n\n        #Density: rho = N / L^2. A safe density for 2D LJ liquid is ~0.8\n        self.target_density = target_density\n        print(f\"density = {self.target_density}\")\n\n\n        #Special calculation for L to account for massive particle counts that user lets simulation determine L for\n        min_L = np.sqrt(N / self.target_density)\n        if L is None:\n            self.L = min_L\n        else:\n            #If there is a provided L, make sure it isn't too small (can lead to particles spawning on each other which breaks the simulation)\n            if L < min_L:\n                print(f\"L={L} is too small for N={N}. Using L={min_L:.2f} instead\")\n                self.L = min_L\n            else:\n                self.L = L\n        \n        #State Arrays\n        self.pos = np.zeros((N, 2))\n        self.vel = np.zeros((N, 2))\n        self.forces = np.zeros((N, 2))\n        \n        #Cell list parameters\n        self.cell_size = rcut\n        self.nx = int(self.L / self.cell_size)\n        self.ny = int(self.L / self.cell_size)\n        \n        self.init_positions()\n        #self.init_velocities() < old code, new code inserted right below\n        #special velocity initialization to demonstrate MB convergence\n        if init_mode == \"random\":\n            #Normal mode, this produces a MB-like initial distribution\n            self.init_velocities()\n        elif init_mode == \"const_speed\":\n            #to achieve random direction & constant speed: speed0 * randomized direction\n            angles = 2*np.pi*np.random.rand(N)\n            self.vel = np.column_stack([speed0*np.cos(angles),\n                                        speed0*np.sin(angles)])\n        else:\n            raise ValueError(f\"Incorrect init_mode: {init_mode}\")\n\n        #Record initial position & velocities after building cell list for reproducibility\n        self.forces, self.pe = compute_forces_cell_list(self.pos, self.L, self.rcut, self.epsilon, self.sigma)\n        self.initial_pos = self.pos.copy()\n        self.initial_vel = self.vel.copy()\n\n    \n    def init_positions(self):\n        \"\"\"Initialize positions on a lattice-type grid to prevent overlaps\"\"\"\n        grid_side = int(np.ceil(np.sqrt(self.N)))\n        spacing = self.L / grid_side\n        idx = 0\n        for i in range(grid_side):\n            for j in range(grid_side):\n                if idx < self.N:\n                    self.pos[idx] = [i * spacing + spacing/2, j * spacing + spacing/2]\n                    idx += 1\n\n    def init_velocities(self, temp=1.0):\n        \"\"\"Initialize random velocities and remove COM drift\"\"\"\n        self.vel = np.random.normal(0, np.sqrt(temp), (self.N, 2))\n        #Center of Mass Correction\n        v_cm = np.mean(self.vel, axis=0)\n        self.vel -= v_cm\n\n    \n    def step(self):\n        \"\"\"\n        Velocity verlet integration step following this procedure:\n        Update v (half step velocity update)\n        Update r (full step position update)\n        Compute F (r_new; recomputing forces @ new positions)\n        Update v (finish half step; complete velocity update)\n        \"\"\"\n        #Half-step velocity update\n        self.vel += 0.5 * self.dt * self.forces / self.mass\n        \n        #Position update using half-step velocity\n        self.pos += self.dt * self.vel\n        self.pos = self.pos % self.L #Periodic Boundaries\n        \n        #Recompute forces at new positions (new accelerations & PE)\n        self.forces, self.pe = compute_forces_cell_list(self.pos, self.L, self.rcut, self.epsilon, self.sigma)\n        \n        #Second half-step velocity update\n        self.vel += 0.5 * self.dt * self.forces / self.mass\n        \n        #Calculate KE from updated forces\n        self.ke = 0.5 * self.mass * np.sum(self.vel**2)\n\nprint(\"Simulator class initialized\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"99420f23-77c3-4d32-aac5-af93b9f34d12","cell_type":"code","source":"#Cell 5\n#Simulation Settings:\nPARTICLES = 300 #Self-explanatory; can be significantly increased if GIF generation is turned off\nSTEPS = 1000 #Total amt of steps\nGENERATE_GIF, SAVE_PNG = True, False #Set both to False for a pure physics run, better for simulating large datasets for many steps\n\n#Other settings, don't usually need to change\nINIT_MODE =\"random\" #change to const_speed to demonstrate MB convergence\nSPEED0=3.0 #speed for particles to initialize with; calculated in ____ units, only matters when init_mode is not random\nL_val = 20.0 # _______(explanation of L)\nRCUT=2.5\nTIMESTEP=0.001\nEPSILON=1.0\nSIGMA=1.0\nMASS=1.0\nDENSITY = 0.8\n\n\"\"\"\nUse these settings to touch the memory limit of the simulator:\nSTEPS = 1000      \nPARTICLES = 1000\n#GIF settings:\nFRAMES_PER = 30\nSAVE_EVERY = 6\ninches = 8\npixels = 80\nGENERATE_GIF, SAVE_PNG = True, False\n\"\"\"\n\"\"\"\nUse these settings to demonstrate the lennard-jones curve:\nSTEPS = 1000      \nPARTICLES = 30\nFRAMES_PER = 30\nSAVE_EVERY = 3\ninches = 7\npixels = 60\nGENERATE_GIF, SAVE_PNG = True, False\n\"\"\"\n\n#Initializes simulator using a default value of 20.0 for L if L is 300 or less, anything above uses the simulation class's automatic scaling\n#A safe L is approx sqrt(N / 0.8). setting L_val equal to None will make the simulator autocalculate a safe L value\nif PARTICLES > 300:\n    L_val = None\nsim = Simulator(N=PARTICLES, L=L_val, dt=TIMESTEP, rcut=RCUT, epsilon=EPSILON, sigma=SIGMA, mass = MASS, init_mode=INIT_MODE, speed0=SPEED0, target_density = DENSITY,)\nprint(f\"Simulation = sim initialized with N={sim.N} particles; using L={sim.L}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"65765088-b349-47f8-a9ae-9a037c1eaced","cell_type":"code","source":"#Cell 6\n#Cleans memory to preserve space for repeated simulation\nplt.close('all')\ngc.collect()\n\n#particle & quiver helper functions to dynamically scale particle & arrow size with L\ndef compute_particle_size(L, base_size=80.0, L_ref=20.0):\n    \"\"\"\n    Scales scatter marker area inversely with L^2 so particle visual size remains proportional even when the simulation box changes\n    \"\"\"\n    return base_size * (L_ref / L)**2\n    \ndef compute_quiver_scale(L, base_scale=4.0, L_ref=20.0):\n    \"\"\"\n    Scales quiver arrow lengths, matplotlib quiver uses arrow_length ∝ 1/scale so to keep arrows proportional as L increases:\n    new_scale = base_scale * (L / L_ref)\n    \"\"\"\n    return base_scale * (L / L_ref)\n    \ndef setup_plot_axes(ax, L, rcut):\n    ax.set_xlim(0, L)\n    ax.set_ylim(0, L)\n    ax.set_aspect(\"equal\")\n    \n    cell_size = rcut\n    nx = int(L / cell_size)\n    ny = int(L / cell_size)\n    for i in range(nx + 1):\n        ax.axvline(i * cell_size, color=\"gray\", linewidth=0.4, alpha=0.25, zorder=0)\n    for j in range(ny + 1):\n        ax.axhline(j * cell_size, color=\"gray\", linewidth=0.4, alpha=0.25, zorder=0)\n\nprint(\"Visual element helpers initialized\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"3ef6693d-b3ec-48a4-a188-cf8fcd4ce113","cell_type":"code","source":"#Cell 7\n#Visualization settings:\nFRAMES_PER = 45 #Frames displayed per second\nSAVE_EVERY = 6 #Saves every nth frame\ninches = 8\npixels = 80\n\n#Execution logic:\nif GENERATE_GIF:\n    gif_path = 'trajectory_visualization.gif'\n    print(f\"GIF generation turned on\\nFrames will be saved to path {gif_path}\")\n    \n    #Creates the figure\n    fig, ax = plt.subplots(figsize=(inches, inches), dpi=pixels)\n    setup_plot_axes(ax, sim.L, sim.rcut)\n\n    #Initializes visual elements\n    speed = np.linalg.norm(sim.vel, axis=1)\n    scat = ax.scatter(sim.pos[:,0], sim.pos[:,1], c=speed, cmap='plasma', s=compute_particle_size(sim.L), zorder=2, edgecolors='black', linewidth=0.5, vmin=0, vmax=2.5)\n    quiv = ax.quiver(sim.pos[:,0], sim.pos[:,1], sim.vel[:,0], sim.vel[:,1], color='black', alpha=0.6, angles='xy', scale_units='xy', scale=compute_quiver_scale(sim.L), width=0.003, zorder=3)\n    title_text = ax.text(0.5, 1.01, \"\", transform=ax.transAxes, ha='center', fontweight='bold')\n    print(\"Initialized visual elements\")\n    \n    #Run loop with ImageIO writer; uses streaming to preserve RAM    \n    with imageio.get_writer(gif_path, mode='I', fps=FRAMES_PER, loop=0) as writer:\n        for s in range(STEPS):\n            sim.step()\n            \n            if s % SAVE_EVERY == 0:\n                #Update visual data\n                speed = np.linalg.norm(sim.vel, axis=1)\n                scat.set_offsets(sim.pos)\n                scat.set_array(speed)\n                scat.set_sizes(np.full(sim.N, compute_particle_size(sim.L)))\n                quiv.set_offsets(sim.pos)\n                quiv.set_UVC(sim.vel[:,0], sim.vel[:,1])\n                quiv.scale = compute_quiver_scale(sim.L)\n                title_text.set_text(f\"Step {s} | N={sim.N}\")\n\n                #Render to buffer\n                buf = io.BytesIO()\n                fig.savefig(buf, format='png')\n                buf.seek(0)\n                writer.append_data(imageio.imread(buf))\n                buf.close()\n                \n            if s * 10 % STEPS == 0:\n                print(f\"Step {s}/{STEPS} completed\")\n\n    plt.close(fig)\n    print(f\"Step {STEPS}/{STEPS} completed\")\n    print(\"GIF complete\")\n\nelse:\n    print(\"GIF generation turned off. Try running next cell.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"1b594c68-c128-4b32-bb32-d0ad7e2256ba","cell_type":"code","source":"#Cell 8\n#pure computation\nif not GENERATE_GIF:\n    if SAVE_PNG:\n        png_path_initial = 'initial_state.png'\n        print(f\"Saving initial state snapshot to {png_path_initial}\")\n        fig, ax = plt.subplots(figsize=(inches, inches), dpi=pixels)\n        setup_plot_axes(ax, sim.L, sim.rcut)\n        speed = np.linalg.norm(sim.vel, axis=1)\n        #Particles\n        ax.scatter(sim.pos[:,0], sim.pos[:,1], c=speed, cmap='plasma', \n                   s=compute_particle_size(sim.L), zorder=2, edgecolors='black', linewidth=0.5, vmin=0, vmax=2.5)\n        #Velocity Arrows\n        ax.quiver(sim.pos[:,0], sim.pos[:,1], sim.vel[:,0], sim.vel[:,1],\n                  color='black', alpha=0.6, angles='xy', scale_units='xy', \n                  scale=compute_quiver_scale(sim.L), width=0.003, zorder=3)      \n        ax.set_title(f\"Initial State | N={sim.N}\")\n        fig.savefig(png_path_initial)\n        plt.close(fig)\n\n    print(\"Running pure physics simulation\")\n    start_time = time.time()\n    for s in range(STEPS):\n        sim.step()\n        #Prints progress 10 times across the entire simulation\n        if s * 10 % STEPS == 0:\n            print(f\"Step {s}/{STEPS} completed\")\n\n            \n    elapsed = time.time() - start_time\n    print(f\"Step {STEPS}/{STEPS} completed\")\n    print(f\"Simulation finished in {elapsed:.4f} seconds\")\n    print(f\"Performance: {(STEPS/elapsed):.2f} steps per second\")\n\n    #Plot final state if requested\n    if SAVE_PNG:\n        png_path_final = 'final_state.png'\n        print(f\"Saving final state snapshot to {png_path_final}\")\n        fig, ax = plt.subplots(figsize=(inches, inches), dpi=pixels)\n        setup_plot_axes(ax, sim.L, sim.rcut)\n        speed = np.linalg.norm(sim.vel, axis=1)\n        #Particles\n        ax.scatter(sim.pos[:,0], sim.pos[:,1], c=speed, cmap='plasma', \n                   s=compute_particle_size(sim.L), zorder=2, edgecolors='black', linewidth=0.5, vmin=0, vmax=2.5)\n        #Velocity Arrows\n        ax.quiver(sim.pos[:,0], sim.pos[:,1], sim.vel[:,0], sim.vel[:,1],\n                  color='black', alpha=0.6, angles='xy', scale_units='xy', \n                  scale=compute_quiver_scale(sim.L), width=0.003, zorder=3)      \n        ax.set_title(f\"Final State (Step {STEPS}) | N={sim.N}\")\n        fig.savefig(png_path_final)\n        plt.close(fig)\nelse:\n    print(\"GIF generation enabled. Please run next cell for step visualization\")","metadata":{"scrolled":true,"trusted":true},"outputs":[],"execution_count":null},{"id":"e5fc40c3-0129-486c-9172-cc36df8b0fa6","cell_type":"code","source":"#Cell 9\n#displays the infinitely looping gif, or the static image of final particle trajectory\nif GENERATE_GIF:\n    from IPython.display import Image, display\n    with open(gif_path, 'rb') as f:\n        display(Image(data=f.read(), format='gif'))\nif SAVE_PNG:\n    from IPython.display import Image, display\n    with open(png_path_initial, 'rb') as f:\n        display(Image(data=f.read(), format='png'))\n    with open(png_path_final, 'rb') as f:\n        display(Image(data=f.read(), format='png'))\nif not GENERATE_GIF and not SAVE_PNG:\n    print(\"Nothing to display! Run the next cells to demonstrate convergence tests.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"3c8effe0-d2e1-4853-9736-3bb031f14c54","cell_type":"code","source":"#Cell 10\n#more helper functions\ndef compute_temperature(v):\n    \"\"\"\n    Computes instantaneous temperature from velocity matrix.\n    Formula: T = 0.5 * <v^2> (assuming m=1, k_B=1)\n    \"\"\"\n    return 0.5 * np.mean(np.sum(v**2, axis=1))\n\ndef mb_pdf_2d(v, T, m=1.0):\n    \"\"\"\n    Theoretical Maxwell-Boltzmann Probability Density Function for 2D.\n    f(v) = (m*v / T) * exp(-m*v^2 / 2T)\n    \"\"\"\n    return (m * v / T) * np.exp(-m * v**2 / (2*T))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"e45cda28-f8c1-4518-9583-ffe0b9442238","cell_type":"code","source":"#Cell 11\ntotal_bins = 25\n\ndef analyze_distribution(velocities, step_label, ax=None, detailed_stats=False):\n    \"\"\"\n    Plots the velocity histogram against the theoretical MB curve.\n    If detailed_stats=True, computes and prints L1 and Chi-sq error metrics.\n    \"\"\"\n    if ax is None:\n        fig, ax = plt.subplots(figsize=(10, 6))\n\n    #Calculate temp & speeds\n    speeds = np.linalg.norm(velocities, axis=1)\n    T_meas = compute_temperature(velocities)\n    \n    #Plot histogram\n    count, bins, _ = ax.hist(speeds, bins=total_bins, density=True, \n                             alpha=0.6, color='dodgerblue', edgecolor='black', label='Sim1 Data')\n    \n    #Theoretical MB curve\n    bin_centers = 0.5 * (bins[:-1] + bins[1:])\n    v_smooth = np.linspace(0, bins.max(), 200)\n    pdf_smooth = mb_pdf_2d(v_smooth, T_meas)\n    ax.plot(v_smooth, pdf_smooth, 'r--', linewidth=2, label=f'MB Expected (T={T_meas:.2f})')\n    \n    #Formatting\n    ax.set_title(f\"Velocity Distribution @ Step {step_label}\")\n    ax.set_xlabel(\"Speed |v|\")\n    ax.set_ylabel(\"PDF\")\n    ax.grid(True, alpha=0.3)\n    if detailed_stats:\n        ax.legend()\n\n    #Error metrics quantified\n    if detailed_stats:\n        pdf_theory_bins = mb_pdf_2d(bin_centers, T_meas)\n        dv = bins[1] - bins[0]\n        abs_err = np.abs(count - pdf_theory_bins)\n        L1_err = np.sum(abs_err * dv)\n        chi_sq = np.sum((abs_err**2) / (pdf_theory_bins + 1e-12))\n        \n        print(f\"Verification step {step_label}\")\n        print(f\"Measured temp: {T_meas:.3f}\")\n        print(f\"L1 error: {L1_err:.4f}\") \n        print(f\"Chi-square: {chi_sq:.4f}\")\n        print(f\"Max bin error: {np.max(abs_err):.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"0fdce368-f762-4cba-a8bb-23098c017651","cell_type":"code","source":"#Cell 12\n\n#Settings\nPARTICLES1 = 100000\nspeed0 = 3.0\nsnapshot_steps = [0, 1, 5, 10, 25, 50, 75, 100, 10000] # Checkpoints\nSTEPS = max(snapshot_steps)\n\nsim1 = Simulator(N=PARTICLES1, L=None, init_mode=\"const_speed\", speed0=speed0)\n\n#sim1 = sim\nprint(f\"Initialized N={sim1.N} particles with constant speed |v|={SPEED0}\")\n\n#Storage\nsnapshots = {} #Stores {step: velocity_array}\nsim1.step()\nsnapshots[0] = sim1.vel.copy()\n\n#Run Simulation Loop\nprint(f\"Simulating {STEPS} steps\")\nfor s in range(1, STEPS + 1):\n    sim1.step()\n    if s in snapshot_steps:\n        snapshots[s] = sim1.vel.copy()\n        print(f\"Recorded snapshot at step {s}\")\n\nprint(\"Simulation complete.\\n\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"349a2284-c482-49ef-bbd6-921c7b1a61b3","cell_type":"code","source":"#Cell 13\nprint(\"Visualizing convergence\")\ncols = 3\nrows = int(np.ceil(len(snapshot_steps) / cols))\nfig, axes = plt.subplots(rows, cols, figsize=(15, 4 * rows))\naxes = axes.flatten()\n\nfor idx, step in enumerate(snapshot_steps):\n    if step in snapshots:\n        analyze_distribution(snapshots[step], step, ax=axes[idx], detailed_stats=False)\n    else:\n        axes[idx].axis('off')\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"aff5f7cd-e1cd-41bc-b80f-27b4d84aaa41","cell_type":"code","source":"#Cell 14\n#Detailed physics check:\nprint(\"Quantifying MB adherence of constant-initialized MB diagram\")\nplt.figure(figsize=(10,6))\nanalyze_distribution(snapshots[STEPS], STEPS, ax=plt.gca(), detailed_stats=True)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"dac87b92-0e07-4fde-b19e-6babbffabb40","cell_type":"code","source":"def benchmark(simulator_cls, max_pow=18):\n    #Parameters:\n    #Stops around 2^15 particles to keep the runtime reasonable, especially when run without Numba\n    particle_counts = np.logspace(5, max_pow, num=max_pow-4, base=2, dtype=int)\n    STEPS_TO_MEASURE = 50 \n    \n    cpu_times = []\n    gpu_times = []\n    \n    print(f\"{'N Particles':<15} | {'CPU (Numba) ms':<15} | {'GPU (Est) ms':<15} | {'Speedup':<15}\")\n    print(\"-\" * 70)\n\n    #Measure (theoretical) GPU runtime for Nvidia 3060\n    #GPU Time = kernel launch latency + (compute time / parallelism)\n            #kernel launch latency: ~45ms for data transfer per block of steps\n            #compute time: small slope because cores divide the work\n    gpu_overhead_ms = 45.0 \n    gpu_parallel_capacity = 43008\n    ms_per_compute_wave = 0.5\n\n    #PCIe Gen 4.0 x16 bus speed, 32 bytes per particle (pos vector + vel vector + padding) / 16 GB/s\n    pci_transfer_ms_per_p = 0.000002\n\n    #Benchmark loop\n    for N in particle_counts:\n        \n        #Initialize simulator with L=none to scale box to target density (0.8)\n        #Deny print outputs during init\n        with contextlib.redirect_stdout(open(os.devnull, 'w')):\n            sim = simulator_cls(N=N, L=None, init_mode=\"const_speed\", speed0=1.0)\n\n        #Measure (real & numba optimized) CPU runtime\n        t_start = time.perf_counter()\n        for _ in range(STEPS_TO_MEASURE):\n            sim.step()\n        t_end = time.perf_counter()\n        \n        total_cpu_ms = (t_end - t_start) * 1000\n        cpu_times.append(total_cpu_ms)\n\n        #Calculate GPU runtime\n        transfer_time = N * pci_transfer_ms_per_p\n        waves_needed = np.ceil(N / gpu_parallel_capacity)\n        compute_time = waves_needed * ms_per_compute_wave * STEPS_TO_MEASURE\n        total_gpu_ms = gpu_overhead_ms + transfer_time + compute_time\n\n        \n        gpu_times.append(total_gpu_ms)\n        \n        #Log results\n        speedup = total_cpu_ms / total_gpu_ms\n        print(f\"{N:<15} | {total_cpu_ms:<15.1f} | {total_gpu_ms:<15.1f} | {speedup:<15.2f}x\")\n\n    #Visualization:\n    plot_results(particle_counts, cpu_times, gpu_times, STEPS_TO_MEASURE)\n\ndef plot_results(N_values, cpu_data, gpu_data, steps):\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n\n    #Left plot - real CPU runtime\n    ax1.plot(N_values, cpu_data, 'o-', label='CPU (Numba Measured)', linewidth=2, color='#1f77b4')\n    ax1.plot(N_values, gpu_data, 's--', label='GPU (Theoretical)', linewidth=2, color='#ff7f0e')\n    \n    ax1.set_xscale('log', base=2)\n    ax1.set_yscale('log')\n    ax1.set_xlabel('Number of Particles (N)')\n    ax1.set_ylabel(f'Total Runtime for {steps} Steps (ms)')\n    ax1.set_title(f'CPU vs Theoretical GPU')\n    ax1.grid(True, which=\"both\", ls=\"--\", alpha=0.4)\n    ax1.legend()\n\n    #Right plot - GPU speedup (theoretical)\n    speedups = np.array(cpu_data) / np.array(gpu_data)\n    ax2.plot(N_values, speedups, 'd-', color='#2ca02c', linewidth=2)\n    ax2.axhline(1.0, color='red', linestyle=':', label='crossover')\n    \n    ax2.set_xscale('log', base=2)\n    ax2.set_xlabel('Number of Particles (N)')\n    ax2.set_ylabel('Speedup factor')\n    ax2.set_title('Projected GPU speedup')\n    ax2.grid(True, which=\"major\", ls=\"-\", alpha=0.4)\n    ax2.legend()\n\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"09bd20da-f34a-41a9-b360-8d4805b1e48a","cell_type":"code","source":"#Run the benchmark\nup_to = 18\nbenchmark(Simulator, max_pow=up_to)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"76b2f141-778b-42d9-991e-f86865ab08df","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"70ce1fa1-df45-4270-bc7d-de67741fa113","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}